{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image outside of the function to avoid reading it multiple times\n",
    "image = cv2.imread(\"image.jpg\")\n",
    "\n",
    "def image_correction(src_points, dst_points):\n",
    "    # Define original and destination points\n",
    "    src_pts = np.array(src_points, dtype=np.float32)\n",
    "    dst_pts = np.array(dst_points, dtype=np.float32)\n",
    "\n",
    "    # Calculate perspective transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "\n",
    "    # Apply perspective transformation\n",
    "    corrected_image = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Display original and corrected images\n",
    "    cv2.imshow(\"Original Image\", image)\n",
    "    cv2.imshow(\"Corrected Image\", corrected_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "src_points = [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]  # Original image points\n",
    "dst_points = [(u1, v1), (u2, v2), (u3, v3), (u4, v4)]  # Destination points\n",
    "\n",
    "image_correction(src_points, dst_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def create_mask(image, json_string):\n",
    "    # 解析json字符串\n",
    "    points_info = json.loads(json_string)\n",
    "    points = np.array(points_info['points'])  # 假设points字段包含电视机的四个顶点\n",
    "\n",
    "    # 创建一个全0的mask，大小和输入图片一致\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # 使用cv2.fillPoly方法填充mask\n",
    "    cv2.fillPoly(mask, [points], 255)\n",
    "\n",
    "    return mask\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "def create_model(num_classes):\n",
    "    model = models.segmentation.fcn_resnet50(weights='DEFAULT')\n",
    "\n",
    "    model.classifier[4] = torch.nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "batch_size = 1\n",
    "summary(model, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, dataloader, device, optimizer, criterion, num_epochs):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(inputs)['out']\n",
    "\n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
